{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "import albumentations as A\n",
    "\n",
    "import wandb\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'TRAIN_PATH': \"D:/Documents/GitHub/image_pipeline/data/aerial-cactus-identification/train/\",\n",
    "    'TRAIN_FILE': \"D:/Documents/GitHub/image_pipeline/data/aerial-cactus-identification/train.csv\",\n",
    "    'DEVICE': torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"),\n",
    "    'TARGET_VAR': \"has_cactus\",\n",
    "    'FOLD_NUMBER': 5,\n",
    "    'IMAGE_ID': \"id\",\n",
    "    'IMAGE_EXT': \".jpg\",\n",
    "    'IMAGE_SIZE': (32, 32),\n",
    "    'EPOCHS': 5,\n",
    "    'TRAIN_BS': 32,\n",
    "    'VALID_BS': 16,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Augmentations = {\n",
    "    'train':\n",
    "        transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [\n",
    "                                     0.229, 0.224, 0.225])\n",
    "            ]\n",
    "        ),\n",
    "    'valid':\n",
    "        transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [\n",
    "                                     0.229, 0.224, 0.225])\n",
    "            ]\n",
    "        )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PETFINDER_DATASET:\n",
    "    '''\n",
    "    Pytorch class to define an image dataset\n",
    "    image_path : must be a list of path to individual images like \"data/image_001.png\"\n",
    "    resize : if not None, image will be resized to this size, MUST BE A TUPLE\n",
    "    label : labels for each image of their class\n",
    "    transforms : if not None, transform will be applied on images\n",
    "    '''\n",
    "\n",
    "    def __init__(self, image_path, resize=None, label=None, transforms=None):\n",
    "        self.image_path = image_path\n",
    "        self.resize = resize\n",
    "        self.label = label\n",
    "        self.transforms = transforms\n",
    "\n",
    "    #RETURN THE LENGHT OF THE DATASET\n",
    "    def __len__(self):\n",
    "        return len(self.image_path)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        #LOADING IMAGES\n",
    "        image = Image.open(self.image_path[item])\n",
    "\n",
    "        #RESIZING IMAGES\n",
    "        if self.resize is not None:\n",
    "            image = image.resize(\n",
    "                (self.resize[1], self.resize[0]), resample=Image.BILINEAR\n",
    "            )\n",
    "\n",
    "        #APPLYING DATA AUGMENTATIONS TO IMAGE DATA\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        if self.label is not None:\n",
    "            label = self.label[item]\n",
    "            return {\n",
    "                \"images\": image,\n",
    "                \"labels\": torch.tensor(label, dtype=torch.float32),\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"images\": image,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RESNET18(nn.Module):\n",
    "    def __init__(self, n_class=2, pretrain=True):\n",
    "        super(RESNET18, self).__init__()\n",
    "\n",
    "        self.base_model = models.resnet18(pretrained=pretrain)\n",
    "        in_features = self.base_model.fc.out_features\n",
    "        #self.nb_features = self.base_model.fc.in_features\n",
    "        self.l0 = nn.Linear(in_features, n_class)\n",
    "\n",
    "    def forward(self, image):\n",
    "        x = self.base_model(image)\n",
    "        out = self.l0(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:/Documents/GitHub/image_pipeline/data/aerial-cactus-identification/train.csv\")\n",
    "\n",
    "train_img = df[config[\"IMAGE_ID\"]].values.tolist()\n",
    "train_img = [os.path.join(config[\"TRAIN_PATH\"], os.path.splitext(i)[0] + config[\"IMAGE_EXT\"]) for i in train_img]\n",
    "train_labels = df[config[\"TARGET_VAR\"]].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING DATASET\n",
    "train_dataset = PETFINDER_DATASET(\n",
    "    image_path=train_img,\n",
    "    resize=config[\"IMAGE_SIZE\"],\n",
    "    label=train_labels,\n",
    "    transforms=Augmentations[\"train\"]\n",
    ")\n",
    "\n",
    "# TRAINING DATALOADER\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=config[\"TRAIN_BS\"], shuffle=True, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7a3ff81405b9811006df8683876ff5d31c6a619ea927c81211f067fbc6cf341"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('Torch-37': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
